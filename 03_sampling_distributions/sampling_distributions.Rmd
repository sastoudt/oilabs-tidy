---
title: "Foundations for statistical inference - Sampling distributions"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE,message=FALSE}
library(learnr)
library(tidyverse)
library(gradethis)
library(openintro)
library(infer)
tutorial_options(
  # use gradethis for checking
  exercise.checker = gradethis::grade_learnr
  )
knitr::opts_chunk$set(echo = FALSE)

global_monitor <- tibble(
  scientist_work = c(rep("Benefits", 80000), rep("Doesn't benefit", 20000))
)
```

## Logistics

This lab will occur remotely and in groups of three. For those of you participating synchronously, you will find the Zoom room information on [Moodle](https://moodle.smith.edu/). I will assign you to a breakout room with your partner(s) from last week. 

For those participating syncronously I will be available in the main Zoom room to answer questions. If you have a question or technical problem, click the "Ask for Help" button (it looks like a question mark) in the meeting controls, and I will be alerted to join your breakout room.  

For those of you participating asynchronously, alert me to technical challengs over Slack DM, and I will get back to you as soon as possible. For questions about the content of the lab, please sign up for an office hour time block. 

Each of you should be writing and running code, examining output, and answering the exercises throughout the lab. However, you only need to turn in one final lab report. To be clear, everyone submits files to Moodle, but the files can be the same within a group. Today one of you should be the main recorder of answers in the lab document. You will share this document with your teammates. As you work it may be helpful to share your screen. Be sure to switch roles from last week so that someone else is the main recorder. It may be helpful to share your screen. 

You all should also feel free to ask and answer questions amongst yourselves via Zoom if participating synchronously or via Slack if participating asynchronously. Please note at the end of the lab document who you consulted for help.

## Getting started

In this lab, you will investigate the ways in which the statistics from a random 
sample of data can serve as point estimates for population parameters. We're 
interested in formulating a *sampling distribution* of our estimate in order 
to learn about the properties of the estimate, such as its distribution.


### Load packages

In this lab, we will explore and visualize the data using the **tidyverse** suite of packages. 
We will also use the **infer** package for resampling.

Let's load the packages.

```{r load-packages, exercise = T}
library(tidyverse)
library(openintro)
library(infer)
```

### Random samples

We will take some random samples and build sampling distributions
in this lab. This means that each time you rerun the sampling code, you will get different answers. This is not ideal as your answers would have to change each time you reran code. By "setting a seed" at the start of your lab you tell the random number generator where to start in its sequence of random numbers (so you'll get the same answer each time you rerun the code in the same order). You can think of the number you pick for `set.seed()` as a bookmark for the sampling algorithm.

Talking more about this is beyond the scope of the class, but if you are interested, I point you to Kellie Ottoboni's cool work on [sampling in R](http://www.kellieottoboni.com/posts/2019/01/random-problems-with-r/).

```{r set-seed, exercise = T}
set.seed(818155)
```

## The data

A 2019 Gallup report states the following:

>The premise that scientific progress benefits people has been embodied in discoveries throughout the ages -- from the development of vaccinations to the explosion of technology in the past few decades, resulting in billions of supercomputers now resting in the hands and pockets of people worldwide. Still, not everyone around the world feels science benefits them personally. 
>
>**Source:** [World Science Day: Is Knowledge Power?](https://news.gallup.com/opinion/gallup/268121/world-science-day-knowledge-power.aspx)

The Wellcome Global Monitor finds that 20% of people globally do not believe that the work scientists do benefits people like them.
In this lab, you will assume this 20% is a true population proportion and learn about how sample proportions can vary from sample to sample by taking smaller samples from the population. 
We will first create our population assuming a population size of 100,000. 
This means 20,000 (20%) of the population think the work scientists do does not 
benefit them personally and the remaining 80,000 think it does.

```{r, data, exercise = T}
global_monitor <- tibble(
  scientist_work = c(rep("Benefits", 80000), rep("Doesn't benefit", 20000))
)
```

The `tibble()` function makes a tidy data frame. The name of the data frame is `global_monitor` and the name of the variable that contains responses to the question *"Do you believe that the work scientists do benefit people like you?"* is `scientist_work`. To populate this variable we `c`ombine the following two groups: `rep`eat "Benefits 80,000 times and `rep`eat ``Doesn't benefit" 20,000 times.

We can quickly visualize the distribution of these responses using a bar plot. Note that `coord_flip()` makes the bars go left to right instead of top to bottom to save space on the page.

```{r bar-plot-pop, exercise = T}
ggplot(global_monitor, aes(x = scientist_work)) +
  geom_bar() +
  labs(
    x = "", y = "",
    title = "Do you believe that the work scientists do benefit people like you?"
  ) +
  coord_flip() 
```

We can also obtain summary statistics to confirm we constructed the data frame correctly. `count` is a shortcut to `group_by(scientist_work) %>% summarise(n = n())`

```{r summ-stat-pop, exercise = T}
global_monitor %>%
  count(scientist_work) 

global_monitor %>%
  count(scientist_work) %>%
  mutate(p = n /sum(n))
```

## The unknown 

In this lab, you have access to the entire population, but this is rarely the case in real life. 
Gathering information on an entire population is often extremely costly or impossible. 
Because of this, we often take a sample of the population and use that to understand the properties of the population.

If you are interested in estimating the proportion of people who don't think the work scientists do benefits them, you can use the `slice_sample` command to survey the population.

```{r samp1, exercise = T}
samp1 <- global_monitor %>%
  slice_sample(n = 50)
```

This command collects a simple random sample of size 50 from the `global_monitor` dataset, and assigns the result to `samp1`. 
This is similar to randomly drawing names from a hat that contains the names of all in the population.
Working with these 50 names is considerably simpler than working with all 100,000 people in the population.

Compare the proportions in the sample to the proportions in the population. Label the proportions in the sample `p_hat` to signal that it is a sample statistic rather than the true population parameter `p`. 

```{r comparesamp-setup}
samp1 <- global_monitor %>%
  slice_sample(n = 50)
```

```{r comparesamp, exercise = TRUE}
global_monitor %>%
  count(scientist_work) %>%
  mutate(p = n /sum(n))

___ %>% 
  count(___) %>%
  mutate(___ = n/sum(n))
```

```{r comparesamp-solution}
global_monitor %>%
  count(scientist_work) %>%
  mutate(p = n /sum(n))

samp1 %>% 
  count(scientist_work) %>%
  mutate(p_hat = n/sum(n))

```

```{r comparesamp-check}
gradethis::grade_code()
```

If you're interested in estimating the proportion of all people who do not believe that the work scientists do benefits them, but you do not have access to the population data, your best single guess is the sample mean that you calculated above.

## More sampling

Depending on which 50 people you selected, your estimate could be a bit above 
or a bit below the true population proportion. 
In general, though, the sample proportion turns out to be a pretty good estimate of the true population proportion, and you were able to get it by sampling less than 1% of the population.

Take a second sample, also of size 50, and call it `samp2`. 

```{r anothersamp, exercise = TRUE}
___ <- global_monitor %>%
  slice_sample(n = ___)
```

```{r anothersamp-solution}
samp2 <- global_monitor %>%
  slice_sample(n = 50)
```

```{r anothersamp-check}
# check code
gradethis::grade_code()
```

How does the sample proportion of `samp2` compare with that of `samp1`? 

```{r anothersampcompare, exercise = TRUE}
___ %>% 
  ___(scientist_work) %>%
  ___(p_hat = n/sum(n))
```


```{r anothersampcompare-solution}
samp2 %>% 
  count(scientist_work) %>%
  mutate(p_hat = n/sum(n))
```

```{r anothersampcompare-check}
# check code
gradethis::grade_code()
```

```{r samplesize}
question("Suppose we took two 
    more samples, one of size 100 and one of size 1000. Which would you think 
    would provide a more accurate estimate of the population proportion?",
    answer("The sample of size 100"),
    answer("The sample of size 1000", correct = T),
    answer("They both would provide the same level of accuracy"),
    allow_retry = TRUE,
    random_answer_order = F
  )
```

## Sampling distribution

Not surprisingly, every time you take another random sample, you might get a different sample proportion. 
It's useful to get a sense of just how much variability you should expect when estimating the population mean this way. 
The distribution of sample proportions, called the *sampling distribution (of the proportion)*, can help you understand this variability. 
In this lab, because you have access to the population, you can build up the sampling distribution for the sample proportion by repeating the above steps many times. 
Here, we use R to take 15,000 different samples of size 50 from the population, calculate the proportion of responses in each sample, filter for only the *Doesn't benefit* responses, and store each result in a vector called `sample_props50`. 
Note that we specify that `replace = TRUE` since sampling distributions are constructed by sampling with replacement. We can filter the estimates that correspond to "Doesn't benefit" only as that is our main focus.

```{r iterate, exercise = T}
sample_props50 <- global_monitor %>%
                    rep_sample_n(size = 50, reps = 15000, replace = TRUE) %>%
                    count(scientist_work) 

head(sample_props50)

sample_props50 <- sample_props50 %>%
                    mutate(p_hat = n /sum(n)) %>%
                    filter(scientist_work == "Doesn't benefit")

head(sample_props50)
```


And we can visualize the distribution of these proportions with a histogram.

```{r, showres-setup}
sample_props50 <- global_monitor %>%
                    rep_sample_n(size = 50, reps = 15000, replace = TRUE) %>%
                    count(scientist_work) 

sample_props50 <- sample_props50 %>%
                    mutate(p_hat = n /sum(n)) %>%
                    filter(scientist_work == "Doesn't benefit")
```

```{r, showres, exercise = T}
ggplot(data = sample_props50, aes(x = p_hat)) +
  geom_histogram(binwidth = 0.02) +
  labs(
    x = "p_hat (Doesn't benefit)",
    title = "Sampling distribution of p_hat",
    subtitle = "Sample size = 50, Number of samples = 15000"
  )

```


### What is a sampling distribution?

The idea behind the `rep_sample_n` function is *repetition*. 
Earlier, you took a single sample of size `n` (50) from the population of all people in the population. 
With this new function, you can repeat this sampling procedure `rep` times in order to build a distribution of a series of sample statistics, which is called the **sampling distribution**. 

For some insight into how functions and names change over time, here is some [context](https://github.com/tidymodels/infer/issues/337) on the function naming. `slice_sample()` took over for an older function `sample_n()`. In the next update of the `infer` package, `rep_sample_n()` will become `rep_slice_sample()`.

Note that in practice one rarely gets to build true sampling distributions, because one rarely has access to data from the entire population. 

Without the `rep_sample_n` function, this would be painful. 
We would have to manually run the following code 15,000 times 

```{r sample-code, exercise = T}
sample_props50 <- global_monitor %>%
                    rep_sample_n(size = 50, reps = 15000, replace = TRUE) %>%
                    count(scientist_work) %>%
                    mutate(p_hat = n /sum(n)) %>%
                    filter(scientist_work == "Doesn't benefit")
```

as well as store the resulting sample proportions each time in a separate vector.

Note that for each of the 15,000 times we computed a proportion, we did so from a **different** sample!

To make sure you understand how sampling distributions are built, and exactly
    what the `rep_sample_n` function does, try modifying the code to create a
    sampling distribution of **25 sample proportions** from **samples of size 10**, 
    and put them in a data frame named `sample_props_small`. Print the output. 
  
    
```{r repsamp, exercise = TRUE}
sample_props___ <- global_monitor %>%
                    rep_sample_n(size = ___, reps = ___, replace = TRUE) %>%
                    count(scientist_work) %>%
                    mutate(p_hat = n /sum(n)) %>%
                    filter(scientist_work == "Doesn't benefit")
___
```


```{r repsamp-solution}
sample_props_small <- global_monitor %>%
                    rep_sample_n(size = 10, reps = 25, replace = TRUE) %>%
                    count(scientist_work) %>%
                    mutate(p_hat = n /sum(n)) %>%
                    filter(scientist_work == "Doesn't benefit")
sample_props_small
```

```{r repsamp-check}
# check code
gradethis::grade_code()
```

```{r obs}
question("How many observations are there in this object called `sample_props_small`? Consider what each observation represents.",
    answer("10"),
    answer("25", correct = T),
    answer("20"),
    answer("50"),
    allow_retry = TRUE,
    random_answer_order = F
  )
```

    
## Sample size 

Mechanics aside, let's return to the reason we used the `rep_sample_n` function: to compute a sampling distribution, specifically, the sampling distribution of the proportions from samples of 50 people. 

```{r hist, exercise = T}
ggplot(data = sample_props50, aes(x = p_hat)) +
  geom_histogram(binwidth = 0.02)
```

The sampling distribution that you computed tells you much about estimating the true proportion of people who think that the work scientists do doesn't benefit them. 
Because the sample proportion is an unbiased estimator, the sampling distribution is centered at the true population proportion, and the spread of the distribution indicates how much variability is incurred by sampling only 50 people at a time from the population.

In the remainder of this section, you will work on getting a sense of the effect that sample size has on your sampling distribution.

```{r, diffsampsize, exercise = T}
sample_props_10 <- global_monitor %>%
                    rep_sample_n(size = 10, reps = 5000, replace = TRUE) %>%
                    count(scientist_work) %>%
                    mutate(p_hat = n /sum(n)) %>%
                    filter(scientist_work == "Doesn't benefit")

sample_props_50 <- global_monitor %>%
                    rep_sample_n(size = 50, reps = 5000, replace = TRUE) %>%
                    count(scientist_work) %>%
                    mutate(p_hat = n /sum(n)) %>%
                    filter(scientist_work == "Doesn't benefit")

sample_props_100 <- global_monitor %>%
                    rep_sample_n(size = 100, reps = 5000, replace = TRUE) %>%
                    count(scientist_work) %>%
                    mutate(p_hat = n /sum(n)) %>%
                    filter(scientist_work == "Doesn't benefit")
```

```{r, diffsampsize2, exercise = T}
ggplot(data = sample_props_10, aes(x = p_hat)) +
  geom_histogram(binwidth = 0.02) + xlim(0,1)
ggplot(data = sample_props_50, aes(x = p_hat)) +
  geom_histogram(binwidth = 0.02) + xlim(0,1)
ggplot(data = sample_props_100, aes(x = p_hat)) +
  geom_histogram(binwidth = 0.02) + xlim(0,1)
```


```{r meanchange}
question("How does the mean change as the sample size increases?",
    answer("gets smaller"),
    answer("gets larger"),
    answer("stays about the same", correct = T),
    allow_retry = TRUE,
    random_answer_order = F
  )
```

```{r sdchange}
question("How does the standard error change as the sample size increases?",
    answer("gets smaller", correct = T),
    answer("gets larger"),
    answer("stays about the same"),
    allow_retry = TRUE,
    random_answer_order = F
  )
```

```{r shapechange}
question("How does the shape of the distribution change as the sample size increases?",
    answer("gets rougher"),
    answer("gets smoother"),
    answer("stays about the same", correct = T),
    allow_retry = TRUE,
    random_answer_order = F
  )
```

## Number of replicates

Now we'll keep the sample size at 50 and see what happens when we change the number of replicates.

```{r, diffrepsize, exercise = T}
sample_props_50_small <- global_monitor %>%
                    rep_sample_n(size = 50, reps = 100, replace = TRUE) %>%
                    count(scientist_work) %>%
                    mutate(p_hat = n /sum(n)) %>%
                    filter(scientist_work == "Doesn't benefit")

sample_props_50_medium <- global_monitor %>%
                    rep_sample_n(size = 50, reps = 1000, replace = TRUE) %>%
                    count(scientist_work) %>%
                    mutate(p_hat = n /sum(n)) %>%
                    filter(scientist_work == "Doesn't benefit")

sample_props_50_large <- global_monitor %>%
                    rep_sample_n(size = 50, reps = 10000, replace = TRUE) %>%
                    count(scientist_work) %>%
                    mutate(p_hat = n /sum(n)) %>%
                    filter(scientist_work == "Doesn't benefit")

```

```{r, diffrepsize2, exercise = T}
ggplot(data = sample_props_50_small, aes(x = p_hat)) +
  geom_histogram(binwidth = 0.02) + xlim(0,1)

ggplot(data = sample_props_50_medium, aes(x = p_hat)) +
  geom_histogram(binwidth = 0.02) + xlim(0,1)

ggplot(data = sample_props_50_large, aes(x = p_hat)) +
  geom_histogram(binwidth = 0.02) + xlim(0,1)

```

```{r meanchange2}
question("How does the mean change as the number of replicates increases?",
    answer("gets smaller"),
    answer("gets larger"),
    answer("stays about the same", correct = T),
    allow_retry = TRUE,
    random_answer_order = F
  )
```

```{r sdchange2}
question("How does the standard error change as the number of replicates increases?",
    answer("gets smaller"),
    answer("gets larger"),
    answer("stays about the same", correct = T),
    allow_retry = TRUE,
    random_answer_order = F
  )
```

```{r shapechange2}
question("How does the shape of the distribution change as the number of replicates increases?",
    answer("gets rougher"),
    answer("gets smoother", correct = T),
    answer("stays about the same"),
    allow_retry = TRUE,
    random_answer_order = F
  )
```

## Submit checkpoint

```{r context="server"}
learnrhash::encoder_logic()
```

```{r encode, echo=FALSE}
learnrhash::encoder_ui(
  ui_before = div(strong("Submit your hash in the form below."), br(), br()),
  ui_after  = learnrhash::iframe_ui(
    src = "https://docs.google.com/forms/", ## change link, include name
    width="900px", height= "1000px"
  )
)
```

## Creating a reproducible lab report

For the rest of this lab you will R Markdown to create a reproducible lab report. 
In RStudio, go to New File -> R Markdown... Then, choose From Template and then choose `Lab Report` from the list of templates. Make sure to name the document appropriately and pick a location for the file where you know how to find it on your computer.

See the following video describing how to get started with creating these 
reports for this lab, and all future labs:

[**Basic R Markdown with an OpenIntro Lab**](https://www.youtube.com/watch?v=Pdc368lS2hk)
<iframe width="560" height="315" src="https://www.youtube.com/embed/Pdc368lS2hk" frameborder="0" allowfullscreen></iframe>

**Note: This video was made using `oilabs`. We will NOT be using `oilabs`. Be sure to pick the Lab Report template that goes with `openintro` as shown in screenshot above. Make sure you have `library(openintro)` in your first chunk not `library(oilabs)`.**

## Questions for Lab Report

Answer in an Rmd file based on the lab report template. Remember you will need to load appropriate packages, set a seed, and create the dataset.

```{r}
global_monitor <- tibble(
  scientist_work = c(rep("Benefits", 80000), rep("Doesn't benefit", 20000))
)
```

So far, you have only focused on estimating the proportion of those you think the work scientists doesn't benefit them. 
Now, you'll try to estimate the proportion of those who think it does.


1.  Take a sample of size 15 from the population and calculate the proportion of 
    people in this sample who think the work scientists do enchances their lives. 

2. Using your sample from question one, what is your best point estimate of the population proportion of people who think the work scientists do enchances their lives?

3.  Change your sample size from 15 to 150, then compute the sampling 
    distribution using the same method as above, and store these proportions in a 
    new object called `sample_props150`. 
    
4. Describe the shape of this sampling distribution and compare it to the sampling distribution for a sample size of 15. 
    
## Deliverables

Make sure you have submitted your hash to the Google Form for the first part of the lab.

When you are finished editing your Markdown document click the "Knit" button and choose "Knit to HTML" in the top left corner of RStudio. This will run all of your code and create a formatted document of the output. If you get an error, it means something in your Markdown file isn't right, either an error in code or some error in formatting. Call me into your breakout room, and we will troubleshoot.

Submit your Markdown document and knitted file to [Moodle](https://moodle.smith.edu/) as:

LastName-LastName-LastName-L-03.Rmd  (add a third last name if applicable)

LastName-LastName-LastName-L-03.html

*Due*: Monday (beginning of class time, Eastern time)

* * *

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a> and was adapted by Sara Stoudt.
